# -*- coding: utf-8 -*-
"""Credit Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AX8G2bMALVOi-QszRRHSioWfjQk0HUgL
"""

# Commented out IPython magic to ensure Python compatibility.
# Importing required libraries
import pandas as pd, numpy as np
import matplotlib.pyplot as plt, seaborn as sns
# %matplotlib inline
pd.set_option('float_format', '{:.2f}'.format)


# Ignore Warnings
import warnings
warnings.filterwarnings("ignore")

# Importing the dataset "application_data.csv")
inp0 = pd.read_csv("application_data.csv")

"""## Exploring the application_data Dataset """

inp0.head()

# checking the structure of the data
inp0.shape

# checking for the datatype
inp0.info(null_counts = True, verbose = True)

"""There are around 307k rows and 122 columns.

Of the total 122 columns, there are 106 columns with numerical data type(float64 - 84 and int64 - 22) and 16 columns with object datatype
"""

# setting the max rows to 122
pd.set_option('display.max.columns',122)

# statistical summary of numerical data
inp0.describe()

"""## Check for missing value"""

# inp0.isnull().sum()

percent_missing = inp0.isnull().sum()*100/len(inp0)

for key,value in percent_missing.iteritems():
    print(key,"-",round(value, 2),"%")

"""## Dropping all columns with missing value percentage more than 35%."""

inp0 = inp0.drop(inp0.loc[:,list((100*(inp0.isnull().sum()/len(inp0))>35))].columns, 1)

# checking the percentage of null values after dropping the columns with more than 35%
percent_missing = inp0.isnull().sum()*100/len(inp0)

for key,value in percent_missing.iteritems():
    print(key,"-",round(value, 2),"%")

"""The remaining columns all have the missing value percentage less than the selected threshold value of 35%"""

# rechecking the shape
inp0.shape

"""After removal of the columns with more than 35%, we are left with 73 columns

## Missing Value Analysis

### Analysis `OCCUPATION_TYPE`

- null values = 31.5%
"""

print(inp0.OCCUPATION_TYPE.isnull().value_counts())

"""There are 81301 missing/null values """

plt.figure(figsize = (8,8))
sns.countplot(data = inp0, y = "OCCUPATION_TYPE")
plt.xticks(rotation = 0)
plt.show()

"""**Observations**

1. The `Laborers` have the highest number of loan applications followed by `Sales staff`. 
2. It is better not to impute missing values with mode as it would bring in bias in analysis lateron. Also, the missing values are very high at 31.5% which are at 81301 numbers.

### Analysis of `EXT_SOURCE_3`

- null values = 19.84%
"""

print(inp0.EXT_SOURCE_3.isnull().value_counts())

"""There are 51453 null values"""

inp0.EXT_SOURCE_3.describe()

"""**Observations**

1. The missing values are 19.84% of the total records. 
2. The mean and median are all close. However, since the missing values is high, it is not suitable for imputation.

## Analysis of the below mentioned columns with missing values of 13.52% 

1. AMT_REQ_CREDIT_BUREAU_HOUR
2. AMT_REQ_CREDIT_BUREAU_DAY 
3. AMT_REQ_CREDIT_BUREAU_WEEK
4. AMT_REQ_CREDIT_BUREAU_MON 
5. AMT_REQ_CREDIT_BUREAU_QRT 
6. AMT_REQ_CREDIT_BUREAU_YEAR
"""

inp0[['AMT_REQ_CREDIT_BUREAU_HOUR',
'AMT_REQ_CREDIT_BUREAU_DAY',
'AMT_REQ_CREDIT_BUREAU_WEEK',
'AMT_REQ_CREDIT_BUREAU_MON',
'AMT_REQ_CREDIT_BUREAU_QRT',
'AMT_REQ_CREDIT_BUREAU_YEAR']].describe()

inp0[['AMT_REQ_CREDIT_BUREAU_HOUR',
'AMT_REQ_CREDIT_BUREAU_DAY',
'AMT_REQ_CREDIT_BUREAU_WEEK',
'AMT_REQ_CREDIT_BUREAU_MON',
'AMT_REQ_CREDIT_BUREAU_QRT',
'AMT_REQ_CREDIT_BUREAU_YEAR']].mode()

"""**Observations for the above analysis**

The mode is 0 for all the variable and the missing values is high at 13.52%. 
On account of high missing values, imputation is not suitable as it may bring bias in analysis

## Handling unknown/incorrect values

### Analysis of the `TARGET` column

checking range of values
"""

inp0.TARGET.value_counts()

"""There are no incorrect/unknown data value in the TARGET COLUMN.

### Analysis of the `NAME_CONTRACT_TYPE` column

checking the range of data
"""

inp0.NAME_CONTRACT_TYPE.value_counts()

"""There are no incorrect/unknown data value in the `NAME_CONTRACT_TYPE` column.

## Analysis of the `CODE_GENDER` column

checking range of values
"""

inp0.CODE_GENDER.value_counts()

"""*Gender can be of two types F/M. `XNA` is incorrect gender.*

*Since number of Females applicants are higher, it is better to replace `XNA` with `F`. Hence replacing `XNA` with F*
"""

inp0['CODE_GENDER'] = inp0['CODE_GENDER'].apply(lambda x: 'F' if x == 'XNA' else x)

"""Checking if `XNA` is removed"""

inp0.CODE_GENDER.value_counts()

"""###Checking for incorrect/unknown values for the entire database"""

for i in inp0.columns:
  print(i,'\n')
  print(inp0[i].value_counts(),'\n')

"""### From the above we notice that the columns `NAME_FAMILY_STATUS`,`DAYS_BIRTH`, `DAYS_EMPLOYED`, `DAYS_REGISTRATION`, `DAYS_ID_PUBLISH`, `ORGANIZATION_TYPE` have unknown/incorrect values which need to be adjusted.

### Analysis of the `NAME_FAMILY_STATUS` column
"""

inp0.NAME_FAMILY_STATUS.value_counts(normalize=True)*100

inp0[inp0['NAME_FAMILY_STATUS'] == 'Unknown']

"""Since `Unknown` data seems valid for other values, we will impute the `Unknown` with `Married` as it has the highest number of applicants"""

inp0['NAME_FAMILY_STATUS'] = inp0['NAME_FAMILY_STATUS'].apply(lambda x: 'Married' if x == 'Unknown' else x)

"""### Analysis of the `DAYS_BIRTH` column"""

inp0.DAYS_BIRTH.value_counts()

"""Converting `DAYS_BIRTH` negative values to positive values"""

inp0['DAYS_BIRTH'] = inp0['DAYS_BIRTH'].apply(lambda x: -x if x < 0 else x)

"""### Analysis of the `DAYS_EMPLOYED` column"""

inp0.DAYS_EMPLOYED.value_counts(normalize = True) * 100

"""`DAYS_EMPLOYED` column indicates how many days ago the applicant started working to the day of application

Converting the values to positive
"""

inp0['DAYS_EMPLOYED'] = inp0['DAYS_EMPLOYED'].apply(lambda x: -x if x < 0 else x)

inp0.DAYS_EMPLOYED.value_counts()

"""Days employed cannot be 365243 as it indicated more than 1000 years

Checking further of the incorrect records
"""

inp0.DAYS_EMPLOYED.describe()

"""The mean is skewed due to incorrect days of 365243"""

inp0[inp0['DAYS_EMPLOYED']==365243].head()

"""The `NAME_INCOME_TYPE` is a pensioner in the above cases.
Checking in more detail
"""

inp0[inp0['DAYS_EMPLOYED'] == 365243].NAME_INCOME_TYPE.value_counts()

"""This indicates that the DAYS_EMPLOYED of 365243 is either a pensioner or unemployed.

"""

# plotting a box plot for the DAYS_EMPLOYED
plt.figure(figsize = (25,4))
sns.boxplot(inp0['DAYS_EMPLOYED'])
plt.show()

inp0.DAYS_EMPLOYED.quantile([0.5, 0.7, 0.80, 0.81, 0.85, 0.9, 0.95, 0.99])

"""1. Since pensioners are generally above 60 years and the average days employed can be considered at the 81th percentile for consideration which is 10994 days equivalent to around 30 years 
2. unemployed applicants DAYS_EMPLOYED Can be replaced by 0

### Analysis of the `DAYS_REGISTRATION` column
"""

inp0['DAYS_REGISTRATION'].value_counts(normalize = True).head()

# converting `DAYS_REGISTRATION` to positive
inp0['DAYS_REGISTRATION'] = inp0['DAYS_REGISTRATION'].apply(lambda x: -x if x < 0 else x)

inp0['DAYS_REGISTRATION'].value_counts().head()

"""### Analysis of the `DAYS_ID_PUBLISH` column"""

inp0['DAYS_ID_PUBLISH'].value_counts(normalize = True).head()

# converting `DAYS_ID_PUBLISH` to positive
inp0['DAYS_ID_PUBLISH'] = inp0['DAYS_ID_PUBLISH'].apply(lambda x: -x if x < 0 else x)

inp0['DAYS_ID_PUBLISH'].value_counts().head()

"""### Analysis of the `ORGANIZATION_TYPE` column"""

inp0['ORGANIZATION_TYPE'].value_counts()

"""Occupation Type cannot be XNA.
Replacing XNA with Unknown
"""

inp0['ORGANIZATION_TYPE'] = inp0['ORGANIZATION_TYPE'].apply(lambda x: 'Unknown' if x=='XNA' else x)

"""Checking for any incorrect values"""

inp0['ORGANIZATION_TYPE'].value_counts()

"""## Handling Outlier for numerical data

### CNT_CHILDREN column analysis
"""

inp0['CNT_CHILDREN'].value_counts(normalize = True).sort_values(ascending = False) * 100

plt.subplots(1,2 ,figsize = (20,8))

plt.subplot(1,2,1)
sns.boxplot(inp0.CNT_CHILDREN)
pltname = 'Boxplot of ' + 'CNT_CHILDREN'
plt.title(pltname)

plt.subplot(1,2,2)
sns.distplot(inp0['CNT_CHILDREN'], color = 'blue')
pltname = 'Distplot of ' + 'CNT_CHILDREN'
plt.ticklabel_format(style='plain', axis='x')
plt.title(pltname)

plt.tight_layout(pad = 4)
plt.show()



"""**Observations**

1. From the above, Applicants with children above 2.5 are outliers and are very minimal

**Conslusion**

1. Applicants with more than 3 children are outlier cases

### Analysis of AMT_INCOME_TOTAL column
"""

(inp0['AMT_INCOME_TOTAL'].value_counts(normalize = True).sort_values(ascending=False) * 100).head()

inp0['AMT_INCOME_TOTAL'].describe([0.75,0.99,0.999, 0.9999])

"""Plotting for 99.99 percentile"""

plt.subplots(1,2 ,figsize = (22,8))

plt.subplot(1,2,1)
sns.boxplot(inp0[inp0['AMT_INCOME_TOTAL'] < 2250000].AMT_INCOME_TOTAL)
pltname = 'Boxplot of ' + 'AMT_INCOME_TOTAL'
plt.title(pltname)

plt.subplot(1,2,2)
sns.distplot(inp0[inp0['AMT_INCOME_TOTAL'] < 2250000].AMT_INCOME_TOTAL)
pltname = 'Distplot of ' + 'AMT_INCOME_TOTAL'
plt.title(pltname)

plt.show()

"""**Observations**

1. Applicants with income of 2250000 are clearly outliers and are at 99.99 percentile

### Analysis of CNT_FAM_MEMBERS column
"""

(inp0['CNT_FAM_MEMBERS'].value_counts(normalize = True).sort_values(ascending = False) * 100).head()

inp0['CNT_FAM_MEMBERS'].describe(percentiles = [0.75,0.99,0.999,0.9999])

plt.subplots(1,2 ,figsize = (22,8))

plt.subplot(1,2,2)
sns.boxplot(inp0[inp0['CNT_FAM_MEMBERS'] <= 8].CNT_FAM_MEMBERS)
pltname = 'Boxplot of ' + 'CNT_FAM_MEMBERS'
plt.title(pltname)

plt.subplot(1,2,1)
sns.distplot(inp0[inp0['CNT_FAM_MEMBERS'] <= 8].CNT_FAM_MEMBERS)
pltname = 'Distplot of ' + 'CNT_FAM_MEMBERS'
plt.title(pltname)

plt.show()

"""**Observations**

Applicants with more than 5 family members are outliers

### Analysis of AMT_ANNUITY column
"""

inp0['AMT_ANNUITY'].describe(percentiles = [0.75,0.99,0.999,0.9999])

Q1 = inp0['AMT_ANNUITY'].quantile(0.25)
Q3 = inp0['AMT_ANNUITY'].quantile(0.75)
IQR = Q3 - Q1
print(IQR)

Max_value = (Q3 + 1.5 * IQR)
print("Max value after which the outlier exist: {}".format(Max_value))

plt.subplots(1,2 ,figsize = (22,8))

plt.subplot(1,2,1)
sns.boxplot(inp0.AMT_ANNUITY)
pltname = 'Boxplot of ' + 'AMT_ANNUITY'
plt.title(pltname)

plt.subplot(1,2,2)
sns.distplot(inp0.AMT_ANNUITY)
pltname = 'Distplot of ' + 'AMT_ANNUITY'
plt.title(pltname)

plt.show()

plt.subplots(1,2 ,figsize = (22,8))

plt.subplot(1,2,1)
sns.boxplot(inp0[inp0['AMT_ANNUITY'] <= 61715.25].AMT_ANNUITY)
pltname = 'Boxplot of ' + 'AMT_ANNUITY'
plt.title(pltname)

plt.subplot(1,2,2)
sns.distplot(inp0[inp0['AMT_ANNUITY'] <= 61715.25].AMT_ANNUITY)
pltname = 'Distplot of ' + 'AMT_ANNUITY'
plt.title(pltname)

plt.show()

"""**Observations**
- The outliers exist after 61715.25 (Outlier value is derived using `Max_value` using IQR formula)

**Conclusion**
-  Applicants with `AMT_ANNUITY` above 61715.25 (calculated using IQR) are outliers

### Analysis of AMT_CREDIT column
"""

inp0['AMT_CREDIT'].describe(percentiles = [0.75,0.99,0.999,0.9999])

Q1 = inp0['AMT_CREDIT'].quantile(0.25)
Q3 = inp0['AMT_CREDIT'].quantile(0.75)
IQR = Q3 - Q1
print(IQR)

Max_value = (Q3 + 1.5 * IQR)
print("Max value after which the outlier exist: {}".format(Max_value))

plt.subplots(1,2 ,figsize = (22,8))

plt.subplot(1,2,1)
sns.boxplot(inp0.AMT_CREDIT)
pltname = 'Boxplot of ' + 'AMT_CREDIT'
plt.title(pltname)

plt.subplot(1,2,2)
sns.distplot(inp0.AMT_CREDIT)
pltname = 'Distplot of ' + 'AMT_CREDIT'
plt.title(pltname)

plt.show()

plt.subplots(1,2 ,figsize = (22,8))

plt.subplot(1,2,1)
sns.boxplot(inp0[inp0['AMT_CREDIT'] <= 1616625.0].AMT_CREDIT)
pltname = 'Boxplot of ' + 'AMT_CREDIT'
plt.title(pltname)

plt.subplot(1,2,2)
sns.distplot(inp0[inp0['AMT_CREDIT'] <= 1616625.0].AMT_CREDIT)
pltname = 'Distplot of ' + 'AMT_CREDIT'
plt.title(pltname)

plt.show()

"""**Observations**

- From the above it is clear that credit amount above 1616625.0(derieved using the `MAX_VALUE` in IQR is a outlier

### Analysis of AMT_ANNUITY column
"""

inp0['AMT_ANNUITY'].describe(percentiles = [0.75,0.99,0.999,0.9999])

Q1 = inp0['AMT_ANNUITY'].quantile(0.25)
Q3 = inp0['AMT_ANNUITY'].quantile(0.75)
IQR = Q3 - Q1
print(IQR)

Max_value = (Q3 + 1.5 * IQR)
print("Max value after which the outlier exist: {}".format(Max_value))

plt.subplots(1,2 ,figsize = (22,8))

plt.subplot(1,2,1)
sns.boxplot(inp0.AMT_ANNUITY)
pltname = 'Boxplot of ' + 'AMT_ANNUITY'
plt.title(pltname)

plt.subplot(1,2,2)
sns.distplot(inp0.AMT_ANNUITY)
pltname = 'Distplot of ' + 'AMT_ANNUITY'
plt.title(pltname)

plt.show()

plt.subplots(1,2 ,figsize = (22,8))

plt.subplot(1,2,1)
sns.boxplot(inp0[inp0['AMT_ANNUITY'] <= 61715.25].AMT_ANNUITY)
pltname = 'Boxplot of ' + 'AMT_ANNUITY'
plt.title(pltname)

plt.subplot(1,2,2)
sns.distplot(inp0[inp0['AMT_ANNUITY'] <= 61715.25].AMT_ANNUITY)
pltname = 'Distplot of ' + 'AMT_ANNUITY'
plt.title(pltname)

plt.show()

"""**Observations**

- From the above plots it is clear that the outlier exists after 61715.25 which is also derieved from `MAX_VALUE` in IQR

### Analysis of AMT_GOODS_PRICE column
"""

inp0['AMT_GOODS_PRICE'].describe(percentiles = [0.75,0.99,0.999,0.9999])

Q1 = inp0['AMT_GOODS_PRICE'].quantile(0.25)
Q3 = inp0['AMT_GOODS_PRICE'].quantile(0.75)
IQR = Q3 - Q1
print(IQR)

Max_value = (Q3 + 1.5 * IQR)
print("Max value after which the outlier exist: {}".format(Max_value))

plt.subplots(1,2 ,figsize = (22,8))

plt.subplot(1,2,1)
sns.boxplot(inp0.AMT_GOODS_PRICE)
pltname = 'Boxplot of ' + 'AMT_GOODS_PRICE'
plt.title(pltname)

plt.subplot(1,2,2)
sns.distplot(inp0.AMT_GOODS_PRICE)
pltname = 'Distplot of ' + 'AMT_GOODS_PRICE'
plt.title(pltname)

plt.show()

plt.subplots(1,2 ,figsize = (22,8))

plt.subplot(1,2,1)
sns.boxplot(inp0[inp0['AMT_GOODS_PRICE'] <= 1341000.0].AMT_GOODS_PRICE)
pltname = 'Boxplot of ' + 'AMT_GOODS_PRICE'
plt.title(pltname)

plt.subplot(1,2,2)
sns.distplot(inp0[inp0['AMT_GOODS_PRICE'] <= 1341000.0].AMT_GOODS_PRICE)
pltname = 'Distplot of ' + 'AMT_GOODS_PRICE'
plt.title(pltname)

plt.show()

"""**Observations**

- From the above plots it is clear that the outlier exists after 1341000.0 which is also derieved from `MAX_VALUE` in IQR

## Analysing imbalance of `TARGET` Column
"""

inp0['TARGET'].value_counts(normalize = True).sort_values() * 100

inp0.TARGET.value_counts(normalize=True).plot.pie(autopct='%1.1f%%', startangle=0, shadow=True) 
plt.show()

"""**Observations**

-  There is imbalance in `TARGET` variable based on the % of observations
 - `TARGET` value 1 represents client with payment difficulties (he/she had late payment more than X days on at least one of the first Y installments of the loan) which is 8.1% of the data
 - `TARGET` value 0 represents all other cases than 1. This is 91.9% of the data

# Univariate analysis of categorical variables

### Data Split based on TARGET for further analysis

`TARGET` value 1 represents client with payment difficulties where the applicant had late payment more than X days on at least one of the first Y installments of the loan. This is  8.1% of the data.

`TARGET` value 0 represents ontime payments
"""

inp01 = inp0[inp0['TARGET'] == 1]

inp00 = inp0[inp0['TARGET'] == 0]

"""the data of TARGET column has been categorised as 1 in inp01 and 0 in inp00"""

inp01.TARGET.value_counts()

inp00.TARGET.value_counts()

"""### Analysis of `NAME_CONTRACT_TYPE`"""

# NAME_CONTRACT_TYPE with payment difficulties

inp01['NAME_CONTRACT_TYPE'].value_counts().sort_values()

# NAME_CONTRACT_TYPE with ontime payments

inp00['NAME_CONTRACT_TYPE'].value_counts().sort_values()

"""###COUNTPLOT"""

plt.figure(figsize = [20,8])

plt.subplot(1,2,1)
pltname = 'NAME_CONTRACT_TYPE' + ' of applicants with payment difficulties'
plt.title(pltname)
sns.countplot(x = 'NAME_CONTRACT_TYPE', data = inp01)

plt.subplot(1,2,2)
pltname = 'NAME_CONTRACT_TYPE' + ' of applicants with on-time payments'
plt.title(pltname)
sns.countplot(x = 'NAME_CONTRACT_TYPE', data = inp00)

plt.show()

"""###PIECHART"""

plt.figure(figsize = [15,15])

plt.subplot(1,2,1)
pltname = 'NAME_CONTRACT_TYPE' + ' of applicants with payment difficulties'
plt.title(pltname)
inp01['NAME_CONTRACT_TYPE'].value_counts().plot.pie(autopct='%1.1f%%', labeldistance=None)
plt.legend()

plt.subplot(1,2,2)
pltname = 'NAME_CONTRACT_TYPE' + ' of applicants with on-time payments'
plt.title(pltname)
inp00['NAME_CONTRACT_TYPE'].value_counts().plot.pie(autopct='%1.1f%%',labeldistance=None)

plt.legend()
plt.show()

"""**Observations**

- There is no significant differences in `NAME_CONTRACT_TYPE` b/w applicants with payment difficulties and on-time payments for both the CountPlot and Piechart

**Conclusion**
- `NAME_CONTRACT_TYPE` column does not provide any conclusive evidence in favor of applicants with payment difficulties or on-time payments

### Analysis of `CODE_GENDER`
"""

plt.figure(figsize = [20,8])

plt.subplot(1,2,1)
pltname = 'CODE_GENDER' + ' of applicants with payment difficulties'
plt.title(pltname)
sns.countplot(x = 'CODE_GENDER', data = inp01)

plt.subplot(1,2,2)
pltname = 'CODE_GENDER' + ' of applicants with on-time payments'
plt.title(pltname)
sns.countplot(x = 'CODE_GENDER', data = inp00)

plt.show()

plt.figure(figsize = [15,15])

plt.subplot(1,2,1)
pltname = 'CODE_GENDER' + ' of applicants with payment difficulties'
plt.title(pltname)
inp01['CODE_GENDER'].value_counts().plot.pie(autopct='%1.1f%%', labeldistance=None)
plt.legend()

plt.subplot(1,2,2)
pltname = 'CODE_GENDER' + ' of applicants with on-time payments'
plt.title(pltname)
inp00['CODE_GENDER'].value_counts().plot.pie(autopct='%1.1f%%',labeldistance=None)

plt.legend()
plt.show()

"""**Observations**

- It can be observed from the pie chart that, the percentage of on time payments of male increases by around 9% from on-time payments to applicants with payment difficulties for male.   

**Conclusion**
- There is a weak inference from the `CODE_GENDER` column that males have higher payment difficulty than Female

### Analysis of `FLAG_OWN_REALTY`
"""

plt.figure(figsize = [20,8])

plt.subplot(1,2,1)
pltname = 'FLAG_OWN_REALTY' + ' of applicants with payment difficulties'
plt.title(pltname)
sns.countplot(x = 'FLAG_OWN_REALTY', data = inp01)

plt.subplot(1,2,2)
pltname = 'FLAG_OWN_REALTY' + ' of applicants with on-time payments'
plt.title(pltname)
sns.countplot(x = 'FLAG_OWN_REALTY', data = inp00)

plt.show()

plt.figure(figsize = [15,15])

plt.subplot(1,2,1)
pltname = 'FLAG_OWN_REALTY' + ' of applicants with payment difficulties'
plt.title(pltname)
inp01['FLAG_OWN_REALTY'].value_counts().plot.pie(autopct='%1.1f%%', labeldistance=None)
plt.legend()

plt.subplot(1,2,2)
pltname = 'FLAG_OWN_REALTY' + ' of applicants with on-time payments'
plt.title(pltname)
inp00['FLAG_OWN_REALTY'].value_counts().plot.pie(autopct='%1.1f%%',labeldistance=None)

plt.legend()
plt.show()

"""**Observations**

- There is no significant differences in `FLAG_OWN_REALTY` b/w applicants with payment difficulties and on-time payments for both the CountPlot and Piechart

**Conclusion**
- `FLAG_OWN_REALTY` column does not provide any conclusive evidence in favor of applicants with payment difficulties or on-time payments

### Analysis of `NAME_INCOME_TYPE`
"""

plt.figure(figsize = [20,8])

plt.subplot(1,2,1)
pltname = 'NAME_INCOME_TYPE' + ' of applicants with payment difficulties'
plt.title(pltname)
sns.countplot(x = 'NAME_INCOME_TYPE', data = inp01)
plt.xticks(rotation = 90)

plt.subplot(1,2,2)
pltname = 'NAME_INCOME_TYPE' + ' of applicants with on-time payments'
plt.title(pltname)
sns.countplot(x = 'NAME_INCOME_TYPE', data = inp00)
plt.xticks(rotation = 90)
plt.show()

plt.figure(figsize = [15,15])

plt.subplot(1,2,1)
pltname = 'NAME_INCOME_TYPE' + ' of applicants with payment difficulties'
plt.title(pltname)
inp01['NAME_INCOME_TYPE'].value_counts().plot.pie(autopct='%1.1f%%', labeldistance=None)
plt.legend()

plt.subplot(1,2,2)
pltname = 'NAME_INCOME_TYPE' + ' of applicants with on-time payments'
plt.title(pltname)
inp00['NAME_INCOME_TYPE'].value_counts().plot.pie(autopct='%1.1f%%',labeldistance=None)

plt.legend()
plt.show()

"""**Observations**

- From the Piechart for `NAME_INCOME_TYPE`, we can observe that, working applicants have higher payment difficulties in comparision to commercial associate, pensioner and state servant. 
- The working applicants were 50.8% of the total who had mande ontime payments whereas the same increased to 61.1% for the payment with difficulties.


**Conclusion**
- we can conclude that the working applicants have payment with difficulties.

### Analysis of `NAME_EDUCATION_TYPE`
"""

plt.figure(figsize = [20,8])

plt.subplot(1,2,1)
pltname = 'NAME_EDUCATION_TYPE' + ' of applicants with payment difficulties'
plt.title(pltname)
sns.countplot(x = 'NAME_EDUCATION_TYPE', data = inp01, order = sorted(inp01['NAME_EDUCATION_TYPE'].unique(), reverse = True))
plt.xticks(rotation = 90)

plt.subplot(1,2,2)
pltname = 'NAME_EDUCATION_TYPE' + ' of applicants with on-time payments'
plt.title(pltname)
sns.countplot(x = 'NAME_EDUCATION_TYPE', data = inp00, order = sorted(inp00['NAME_EDUCATION_TYPE'].unique(), reverse = True))
plt.xticks(rotation = 90)
plt.show()

plt.figure(figsize = [15,15])

plt.subplot(1,2,1)
pltname = 'NAME_EDUCATION_TYPE' + ' of applicants with payment difficulties'
plt.title(pltname)
inp01['NAME_EDUCATION_TYPE'].value_counts().plot.pie(autopct='%1.1f%%', labeldistance=None)
plt.legend()

plt.subplot(1,2,2)
pltname = 'NAME_EDUCATION_TYPE' + ' of applicants with on-time payments'
plt.title(pltname)
inp00['NAME_EDUCATION_TYPE'].value_counts().plot.pie(autopct='%1.1f%%',labeldistance=None)

plt.legend()
plt.show()

"""**Observations**

- For `NAME_EDUCATION_TYPE` column, the applicants with Seconday Education level have a slightly higher chances of having payment with difficulties as indicated in the pie chart with increase in contribution to the pool of total applicants of Seconday Education from 70.4% in on-time payments to 78.6% to payment with difficulties. 

**Conclusion**
- For `NAME_EDUCATION_TYPE` column, the applicants with Seconday Education level have weak inference for payment with diffilculties.

### Analysis of `NAME_FAMILY_STATUS`
"""

plt.figure(figsize = [20,8])

plt.subplot(1,2,1)
pltname = 'NAME_FAMILY_STATUS' + ' of applicants with payment difficulties'
plt.title(pltname)
sns.countplot(x = 'NAME_FAMILY_STATUS', data = inp01, order = sorted(inp01['NAME_FAMILY_STATUS'].unique(), reverse = True))
plt.xticks(rotation = 90)

plt.subplot(1,2,2)
pltname = 'NAME_FAMILY_STATUS' + ' of applicants with on-time payments'
plt.title(pltname)
sns.countplot(x = 'NAME_FAMILY_STATUS', data = inp00, order = sorted(inp00['NAME_FAMILY_STATUS'].unique(), reverse = True))
plt.xticks(rotation = 90)
plt.show()

plt.figure(figsize = [15,15])

plt.subplot(1,2,1)
pltname = 'NAME_FAMILY_STATUS' + ' of applicants with payment difficulties'
plt.title(pltname)
inp01['NAME_FAMILY_STATUS'].value_counts().plot.pie(autopct='%1.1f%%', labeldistance=None)
plt.legend()

plt.subplot(1,2,2)
pltname = 'NAME_FAMILY_STATUS' + ' of applicants with on-time payments'
plt.title(pltname)
inp00['NAME_FAMILY_STATUS'].value_counts().plot.pie(autopct='%1.1f%%',labeldistance=None)

plt.legend()
plt.show()

"""**Observations**

- Applicants who are 'Married' are 64.3% with on-timepayments and 60.0% with payment difficulties 
- Applicants who are 'Single/Not Married' are 14.5% with on-timepayments and 17.8% with payment difficulties


**Conclusion**

- Applicants who are 'Married' or 'Widow' make on-time payments better comparatively. However, this is a weak correlation.
- Applicants who are 'Single/not married' have more difficulties with on-time payments comparatively. However, this is a weak correlation.

## Co-relation for numerical columns for both the cases 0 and 1 of TARGET variable
"""

# Coorelation for applicants with on time payments


col_int=list(inp00.select_dtypes('int64').columns)
col_float=list(inp00.select_dtypes('float').columns)

cols=col_int+col_float

Col_Corr = inp00[cols].corr()

print(Col_Corr.unstack().sort_values(ascending=False).drop_duplicates())

# Coorelation for applicants with payment difficulties

col_int=list(inp01.select_dtypes('int64').columns)
col_float=list(inp01.select_dtypes('float').columns)

cols=col_int+col_float

Col_Corr = inp00[cols].corr()

print(Col_Corr.unstack().sort_values(ascending=False).drop_duplicates())

"""**Observations**

The Coorelation top 5 +ve and top 5 -ve are same for applicants with ontime payments and applicants with payment difficulties

## Univariate analysis of numerical variables
"""

# function to calculate Min_Value and Max_value

def fn_IQR_min_max(dataset1,dataset0, column):
    Q1 = dataset1[column].quantile(0.25)
    Q3 = dataset1[column].quantile(0.75)
    IQR = Q3 - Q1
    Min_value1 = (Q1 - 1.5 * IQR)
    Max_value1 = (Q3 + 1.5 * IQR)

    Q1 = dataset0[column].quantile(0.25)
    Q3 = dataset0[column].quantile(0.75)
    IQR = Q3 - Q1
    Min_value0 = (Q1 - 1.5 * IQR)
    Max_value0 = (Q3 + 1.5 * IQR)

    fn_IQR_list = [Min_value1, Max_value1, Min_value0, Max_value0]
    return fn_IQR_list

"""###  Analysis of AMT_INCOME_TOTAL

#### Identifying outlier in both the cases of TARGET variable for AMT_INCOME_TOTAL
"""

# checking for outliers in AMT_INCOME_TOTAL
outlier_AMT_INCOME_TOTAL = fn_IQR_min_max(inp01, inp00, 'AMT_INCOME_TOTAL')

# removing outliers and plotting

plt.figure(figsize = [22,8])
sns.distplot(inp01[inp01['AMT_INCOME_TOTAL'] <= outlier_AMT_INCOME_TOTAL[1]].AMT_INCOME_TOTAL,label = 'Payment difficulties', hist=False)
sns.distplot(inp00[inp00['AMT_INCOME_TOTAL'] <= outlier_AMT_INCOME_TOTAL[3]].AMT_INCOME_TOTAL,label = 'On-Time Payments', hist=False)
plt.legend()
plt.show()

"""**Observations**

- The TARGET column with payment difficulties has a normal distribution wheareas the On-time payments display erratic spikes which has to be analysed further.

###  Analysis of AMT_CREDIT

#### Identifying outlier in both the cases of TARGET variable for AMT_CREDIT
"""

# checking for outliers in AMT_CREDIT
outlier_AMT_CREDIT = fn_IQR_min_max(inp01, inp00, 'AMT_CREDIT')

# removing outliers and plotting

plt.figure(figsize = [22,8])
sns.distplot(inp01[inp01['AMT_CREDIT'] <= outlier_AMT_CREDIT[1]].AMT_CREDIT,label = 'Payment difficulties', hist=False)
sns.distplot(inp00[inp00['AMT_CREDIT'] <= outlier_AMT_CREDIT[3]].AMT_CREDIT,label = 'On-Time Payments', hist=False)
plt.legend()
plt.show()

"""**Observations**

- For `AMT_CREDIT` between 250000 and approximately 650000, there are more applicants with Payment difficulties
- For `AMT_CREDIT` > 750000 and `AMT_CREDIT` < 250000 , there are more applicants with On-Time Payments

###  Analysis of DAYS_BIRTH

#### Identifying outlier in both the cases of TARGET variable for DAYS_BIRTH
"""

# checking for outliers in DAYS_BIRTH
outlier_DAYS_BIRTH = fn_IQR_min_max(inp01, inp00, 'DAYS_BIRTH')

# removing outliers and plotting

plt.figure(figsize = [22,8])
sns.distplot(inp01[inp01['DAYS_BIRTH'] <= outlier_DAYS_BIRTH[1]].DAYS_BIRTH,label = 'Payment difficulties', hist=False)
sns.distplot(inp00[inp00['DAYS_BIRTH'] <= outlier_DAYS_BIRTH[3]].DAYS_BIRTH,label = 'On-Time Payments', hist=False)
plt.legend()
plt.show()

print(15000/365)
print(6500/365)

"""**Observations**

- For `DAYS_BIRTH` between 6500 days and 15000 days which is equivalent to 17 years to 41 years, there are more applicants with Payment difficulties
- On the other way, for `DAYS_BIRTH` > 15000 days which is around 41.1 years, there are more applicants with On-Time Payments

###  Analysis of AMT_GOODS_PRICE

#### Identifying outlier in both the cases of TARGET variable for AMT_GOODS_PRICE
"""

# checking for outliers in AMT_GOODS_PRICE
outlier_AMT_GOODS_PRICE = fn_IQR_min_max(inp01, inp00, 'AMT_GOODS_PRICE')

# removing outliers and plotting

plt.figure(figsize = [22,8])
sns.distplot(inp01[inp01['AMT_GOODS_PRICE'] <= outlier_AMT_GOODS_PRICE[1]].AMT_GOODS_PRICE,label = 'Payment difficulties', hist=False)
sns.distplot(inp00[inp00['AMT_GOODS_PRICE'] <= outlier_AMT_GOODS_PRICE[3]].AMT_GOODS_PRICE,label = 'On-Time Payments', hist=False)
plt.legend()
plt.show()

"""**Observations**

- For `AMT_GOODS_PRICE` between 200000 and 550000 there are more applicants with Payment difficulties
- On the other way, for `AMT_GOODS_PRICE` > 550000, there are more applicants with On-Time Payments

###  Analysis of DAYS_EMPLOYED

#### Identifying outlier in both the cases of TARGET variable for DAYS_EMPLOYED
"""

# checking for outliers in DAYS_EMPLOYED
outlier_DAYS_EMPLOYED = fn_IQR_min_max(inp01, inp00, 'DAYS_EMPLOYED')

# removing outliers and plotting

plt.figure(figsize = [22,8])
sns.distplot(inp01[inp01['DAYS_EMPLOYED'] <= outlier_DAYS_EMPLOYED[1]].DAYS_EMPLOYED,label = 'Payment difficulties', hist=False)
sns.distplot(inp00[inp00['DAYS_EMPLOYED'] <= outlier_DAYS_EMPLOYED[3]].DAYS_EMPLOYED,label = 'On-Time Payments', hist=False)
plt.legend()
plt.show()

print(2000/365)

"""**Observations**

- For `DAYS_EMPLOYED` less than 2000 days which is equivalent to around 5.5 years, there are more applicants with Payment difficulties
- On the other way, for `DAYS_EMPLOYED` > 2000 days which is around 5.5 years, there are more applicants with On-Time Payments

# Bivariate analysis
"""

def outlier_range(dataset,column):
    Q1 = dataset[column].quantile(0.25)
    Q3 = dataset[column].quantile(0.75)
    IQR = Q3 - Q1
    Max_value = (Q3 + 1.5 * IQR)
    return Max_value

"""### Analysis of AMT_INCOME_TOTAL V/S AMT_CREDIT

Outlier identification of `AMT_INCOME_TOTAL` with Payment difficulties
"""

max_value1_AMT_INCOME_TOTAL = outlier_range(inp01,'AMT_INCOME_TOTAL')
max_value1_AMT_INCOME_TOTAL

"""Outlier identification of `AMT_CREDIT` with Payment difficulties"""

max_value1_AMT_CREDIT = outlier_range(inp01,'AMT_CREDIT')
max_value1_AMT_CREDIT

"""Outlier identification of `AMT_INCOME_TOTAL` with ontime payments"""

max_value0_AMT_INCOME_TOTAL = outlier_range(inp00,'AMT_INCOME_TOTAL')
max_value0_AMT_INCOME_TOTAL

"""Outlier identification of `AMT_CREDIT` with ontime payments"""

max_value0_AMT_CREDIT = outlier_range(inp00,'AMT_CREDIT')
max_value0_AMT_CREDIT

# scatter plot with outliers removed

plt.figure(figsize = [20,8])

plt.subplot(1,2,1)
plt.title('Payment difficulties')
sns.scatterplot(x = inp01[inp01['AMT_INCOME_TOTAL'] < max_value1_AMT_INCOME_TOTAL].AMT_INCOME_TOTAL, y = inp01[inp01['AMT_CREDIT'] < max_value1_AMT_CREDIT].AMT_CREDIT, data = inp01)

plt.subplot(1,2,2)
plt.title('On-Time Payments')
sns.scatterplot(x = inp00[inp00['AMT_INCOME_TOTAL'] < max_value0_AMT_INCOME_TOTAL].AMT_INCOME_TOTAL, y = inp00[inp00['AMT_CREDIT'] < max_value0_AMT_CREDIT].AMT_CREDIT, data = inp00)
plt.show()

"""Observations

It is difficult to spot the trend for AMT_INCOME_TOTAL Vs. AMT_CREDIT

## Continuous V/S Categorical variables

### Analysis of NAME_INCOME_TYPE V/S AMT_GOODS_PRICE V/S CODE_GENDER

Outlier identification of `AMT_GOODS_PRICE` with Payment difficulties
"""

max_value1_AMT_GOODS_PRICE = outlier_range(inp01,'AMT_GOODS_PRICE')
max_value1_AMT_GOODS_PRICE

"""Outlier identification of `AMT_GOODS_PRICE` with On-Time Payments"""

max_value0_AMT_GOODS_PRICE = outlier_range(inp00,'AMT_GOODS_PRICE')
max_value0_AMT_GOODS_PRICE

"""Applicants with Payment difficulties"""

inp01.groupby(by = ['NAME_INCOME_TYPE','CODE_GENDER']).AMT_GOODS_PRICE.describe().head()

# ontime payments

inp00.groupby(by = ['NAME_INCOME_TYPE','CODE_GENDER']).AMT_GOODS_PRICE.describe().head()

plt.figure(figsize = [20,12])

plt.subplot(1,2,1)
plt.title('Payment Difficulties')
sns.boxplot(x = 'NAME_INCOME_TYPE', 
            y = inp01[inp01['AMT_GOODS_PRICE'] < max_value1_AMT_GOODS_PRICE]['AMT_GOODS_PRICE'], 
            data = inp01)
plt.xticks(rotation=90)

plt.subplot(1,2,2)
plt.title('On-Time Payments')
sns.boxplot(x = 'NAME_INCOME_TYPE', 
            y = inp00[inp00['AMT_GOODS_PRICE'] < max_value0_AMT_GOODS_PRICE]['AMT_GOODS_PRICE'], 
            data = inp00)
plt.xticks(rotation=90)

plt.show()

"""#Analysis of Previous_Application database"""

inp1 = pd.read_csv("previous_application.csv")

inp1.head()

inp1.info()

inp1.shape()

"""##Merging datasets"""

df_merge = inp0.merge(inp1, left_on='SK_ID_CURR', right_on='SK_ID_CURR', how='inner')

df_merge.head()

df_merge.info()